{%- import "util.jinja.include" as util -%}
{%- set messagegroups = root.messagegroups %}
{% for messagegroupid, messagegroup in messagegroups.items() -%}
{%- set groupname = messagegroupid | pascal -%}
{%- set class_name = (groupname | strip_namespace) + "Producer" %}
# {{ project_name }} - Azure Event Hubs Producer

Auto-generated TypeScript producer for sending CloudEvents to Azure Event Hubs.

## Overview

This library provides a type-safe Event Hubs producer client for {{ groupname }} message group. Built on `@azure/event-hubs` SDK.

## What is Azure Event Hubs?

**Azure Event Hubs** is a fully managed, real-time data ingestion service that:
- **Scales automatically** to handle millions of events per second
- **Supports multiple protocols** including AMQP, Kafka, and HTTPS
- **Provides event replay** with configurable retention (1-90 days)
- **Integrates seamlessly** with Azure services and Stream Analytics

Use cases: Telemetry ingestion, log aggregation, IoT data streams, event sourcing.

## Installation

```bash
npm install
```

## Building

```bash
npm run build
```

## Testing

```bash
npm test
```

## Quick Start

### 1. Using Connection String

```typescript
import { EventHubProducerClient } from '@azure/event-hubs';
import { {{ class_name }} } from './src';

const client = new EventHubProducerClient(
    'Endpoint=sb://namespace.servicebus.windows.net/;SharedAccessKeyName=...;SharedAccessKey=...',
    'event-hub-name'
);

const producer = new {{ class_name }}(client);

{%- set first_message = messagegroup.messages.items() | first %}
{%- if first_message %}
{%- set messageid, message = first_message %}
{%- set messagename = messageid | pascal | strip_namespace %}
{%- set message_body_type = util.body_type(data_project_name, root, message) %}

// Send single event
await producer.send{{ messagename }}({
    // Your {{ message_body_type | strip_namespace }} data here
});
{%- endif %}

await producer.close();
```

### 2. Using Azure Identity (Recommended for Production)

```typescript
import { DefaultAzureCredential } from '@azure/identity';
import { EventHubProducerClient } from '@azure/event-hubs';

const credential = new DefaultAzureCredential();
const client = new EventHubProducerClient(
    'fully-qualified-namespace.servicebus.windows.net',
    'event-hub-name',
    credential
);
```

### 3. Send Batch of Events

```typescript
{%- if first_message %}
await producer.send{{ messagename }}Batch([
    { /* data 1 */ },
    { /* data 2 */ },
    { /* data 3 */ }
]);
{%- endif %}
```

## Available Event Sending Methods

{% for messageid, message in messagegroup.messages.items() -%}
{%- set messagename = messageid | pascal | strip_namespace %}
{%- set message_body_type = util.body_type(data_project_name, root, message) %}
### send{{ messagename }}

**Message Type:** `{{ messageid }}`
**Data Type:** `{{ message_body_type | strip_namespace }}`

```typescript
await producer.send{{ messagename }}(data: {{ message_body_type | strip_namespace }}): Promise<void>
```

Send a single {{ messagename }} event.

### send{{ messagename }}Batch

```typescript
await producer.send{{ messagename }}Batch(dataArray: {{ message_body_type | strip_namespace }}[]): Promise<void>
```

Send multiple {{ messagename }} events in a single batch for better throughput.

{% if message.description -%}
{{ message.description }}
{% endif %}
{% endfor %}

## Configuration Options

### Partition Keys

Control event distribution across partitions:

```typescript
await producer.send{{ messagename }}(data, {
    partitionKey: 'device-123'  // Events with same key go to same partition
});
```

### Custom Properties

Add application-specific metadata:

```typescript
await producer.send{{ messagename }}(data, {
    properties: {
        priority: 'high',
        source: 'device-gateway'
    }
});
```

## Error Handling

```typescript
try {
    await producer.send{{ messagename }}(eventData);
} catch (error) {
    console.error('Failed to send {{ messagename }}:', error);
    // Handle send failure (retry, log, alert, etc.)
}
```

## Best Practices

1. **Reuse producer clients** - create once, use multiple times
2. **Use batch sending** for high-throughput scenarios
3. **Implement retry logic** with exponential backoff
4. **Use partition keys** for ordered processing of related events
5. **Monitor throttling** and adjust send rate accordingly
6. **Use Azure Identity** instead of connection strings for production
{% endfor %}
